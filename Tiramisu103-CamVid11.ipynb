{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from livelossplot import PlotLossesKeras\n",
    "from src import camvid\n",
    "from src import tiramisu\n",
    "from src.utils import history_to_results\n",
    "%matplotlib inline\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.read_table('11_class.txt', sep=r'\\s+', names=['og', 'new'], index_col='og')['new'].to_dict()\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the size to reshape images to before transformation\n",
    "target_size = (360, 480)\n",
    "# the size to crop images to for coarse training\n",
    "coarse_crop = (224, 224)\n",
    "coarse_batch = 3\n",
    "# the size to crop images to for fine tune training\n",
    "fine_crop = (352, 480)\n",
    "fine_batch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all crop dimensions must be divisible by this value due \n",
    "# to the requirement of equal shapes between downsampling \n",
    "# outputs and upsampling inputs imposed by the concatenation\n",
    "# in skip link connections\n",
    "divisible_by = int(2**5)\n",
    "# iterate over all the crop dimensions\n",
    "for dim in coarse_crop + fine_crop:\n",
    "    # raise error if the dimension has a remainder when divided\n",
    "    if dim % divisible_by:\n",
    "        f = 'crop dimension ({}) must be divisible by {}'\n",
    "        f = f.format(dim, divisible_by)\n",
    "        raise ValueError(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coarse Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camvid11 = camvid.CamVid(\n",
    "    mapping=mapping, \n",
    "    target_size=target_size, \n",
    "    crop_size=coarse_crop, \n",
    "    batch_size=coarse_batch\n",
    ")\n",
    "generators = camvid11.generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the next X, y training tuple\n",
    "X, y = next(generators['train'])\n",
    "# transform the onehot vector to an image\n",
    "y = camvid11.unmap(y)\n",
    "# plot the images\n",
    "camvid.plot(X=X[0], y=y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model for the image shape and number of labels\n",
    "model = tiramisu.build_tiramisu((*coarse_crop, 3), camvid11.n,\n",
    "    label_names=camvid11.discrete_to_label_map,\n",
    "    class_weights=camvid11.class_weights,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fit the model with the data. divide the steps per epoch by the \n",
    "# batch size (which is 3 in this case)\n",
    "history = model.fit_generator(generators['train'],\n",
    "    epochs=200,\n",
    "    steps_per_epoch=int(367 / 3),\n",
    "    validation_data=generators['val'],\n",
    "    validation_steps=101,\n",
    "    callbacks=[\n",
    "        LearningRateScheduler(lambda _, lr: 0.995 * lr),\n",
    "        EarlyStopping(monitor='val_acc', patience=100),\n",
    "        PlotLossesKeras(),\n",
    "    ],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_to_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate_generator(generators['test'], steps=233)\n",
    "names = model.metrics_names\n",
    "pd.DataFrame(metrics, names, columns=['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(generator):\n",
    "    X, y = next(generator)\n",
    "    p = model.predict(X)\n",
    "    return X, camvid11.unmap(y), camvid11.unmap(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camvid.plot(X=X[1], y=y[1], y_pred=p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camvid.plot(X=X[2], y=y[2], y_pred=p[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['val'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['val'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['val'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['val'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['test'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['test'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['test'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['test'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize weights to HDF5\n",
    "model.save_weights('models/Tiramisu103-CamVid11-coarse.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear Session\n",
    "\n",
    "remove the current model from memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camvid11 = camvid.CamVid(\n",
    "    mapping=mapping, \n",
    "    target_size=target_size, \n",
    "    crop_size=fine_crop, \n",
    "    batch_size=fine_batch\n",
    ")\n",
    "generators = camvid11.generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the next X, y training tuple\n",
    "X, y = next(generators['train'])\n",
    "# transform the onehot vector to an image\n",
    "y = camvid11.unmap(y)\n",
    "# plot the images\n",
    "camvid.plot(X=X[0], y=y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model for the image shape and number of labels\n",
    "tune_model = tiramisu.build_tiramisu((*fine_crop, 3), camvid11.n,\n",
    "    label_names=camvid11.discrete_to_label_map,\n",
    "    class_weights=camvid11.class_weights,\n",
    "    learning_rate=1e-4,\n",
    ")\n",
    "# load the weights from the coarsely trained model\n",
    "tune_model.load_weights('./models/Tiramisu103-CamVid11-coarse.h5')\n",
    "tune_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fit the model with the data. use a small max queue size to \n",
    "# prevent an OOM error due to large image size\n",
    "history = tune_model.fit_generator(generators['train'],\n",
    "    epochs=200,\n",
    "    steps_per_epoch=int(367 / fine_batch),\n",
    "    validation_data=generators['val'],\n",
    "    validation_steps=101,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_acc', patience=50),\n",
    "        PlotLossesKeras(),\n",
    "    ],\n",
    "    verbose=0,\n",
    "    max_queue_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_to_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tune_model.evaluate_generator(generators['test'], steps=233)\n",
    "names = tune_model.metrics_names\n",
    "pd.DataFrame(metrics, names, columns=['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(generator):\n",
    "    X, y = next(generator)\n",
    "    p = tune_model.predict(X)\n",
    "    return X, camvid11.unmap(y), camvid11.unmap(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['train'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['train'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['train'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['train'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['val'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['val'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['val'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['val'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['test'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['test'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['test'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, p = predict(generators['test'])\n",
    "camvid.plot(X=X[0], y=y[0], y_pred=p[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize weights to HDF5\n",
    "tune_model.save_weights('models/Tiramisu103-CamVid11-fine.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
